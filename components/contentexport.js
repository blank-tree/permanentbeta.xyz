// this is a situational fix for the presentation on 12.04.2019, but not the solution for the import (yet)
// we're currently using the "iA Writer" HTML export here

import React, {Component} from 'react';

export default class Export extends Component {

	render() {
		return(
			<article>
			<h2>Introduction</h2>
			<p>This is a text on the internet. There are many like it but this one is mine;<br/>
			and yours;<br/>
			and everyones;<br/>
			ever changing;<br/>
			never finished.</p>

			<p>I'm going on an adventure, to think and write about the landscape we're currently<sup><a href="#fn1-1593" id="fnr1-1593" title="see footnote" className="footnote">1</a></sup> in and the changes to our collective way of thinking about ourselves and the society<sup><a href="#fn2-1593" id="fnr2-1593" title="see footnote" className="footnote">2</a></sup> we're part of.
			Thinking back, the last two decades marked a drastically shift in the ways individuals and groups communicate with each other in a modern world. The expectation that everyone around us knows how to use (and misuse) the new tools of communication and information seem to unearth the ambiguity of the underlying concepts. With the implementation of this ambiguity into fixed systems – built mostly by private companies – our society also seems to lose the agency to advance them themselves in the future. This is a pessimistic view of <a href="https://en.wikipedia.org/wiki/Digitization" target="_blank">digitization</a> and falls in line with the way of thinking of the <a href="https://en.wikipedia.org/wiki/Swing_Riots" target="_blank">Swing Riots in the 1830s</a>. One could think with the rhetoric used in news articles<sup><a href="#fn3-1593" id="fnr3-1593" title="see footnote" className="footnote">3</a></sup> discussing pitfalls and setbacks – from the point of view of companies working in these fields – that an <a href="https://en.wikipedia.org/wiki/Orwellian"  target="_blank">&quot;Orwellian Dystopia&quot;</a> is the only logical outcome. A worrying outlook, but in my humble opinion is this not the entire story and much of it is still in our – individual and collective – hands.<br/>
			Maybe these changes we're all currently experiencing give us an opportunity not just to reflect the new implementations of everyday interactions, but also to reflect the interactions and concepts they're based on. Grand shifts in society tended to discuss specific variables and rarely society in its entirety, but that is exactly what we're currently undergoing when we try to translate more and more aspects and interactions into the digital realm under the flag of efficiency, and the result is a deadening and confusion amongst our peers and ourselves.</p>

			<p>This essay doesn't only give a highly subjective and opinionated view of the matters at hand, but also challenge the reader with a few obstacles along the way. The structure isn't fixed, the conclusions and views are ever shifting – even while you're currently reading this –, and over time, there will be additional changes I and hopefully other will supply to this essay. You can follow and judge the progression of this construct on the <a href="https://github.com/blank-tree/permanentbeta.xyz" target="_blank">Git-Repository</a><sup><a href="#fn4-1593" id="fnr4-1593" title="see footnote" className="footnote">4</a></sup> or more specifically in the <a href="https://github.com/blank-tree/permanentbeta.xyz/commits/master" target="_blank">commit history</a>.</p>

			<p>Because of the previously described nature of this essay, I'm already providing my conclusion of the following paragraphs: Dividing opinions regarding the internet in dystopian or utopian camps misses the opportunity to think of something in between: The act of the translation into the digital realm itself. This act – combined with the fact that any practice of abstraction and/or translation has to deal with a certain amount of loss of information – offers a working surface to place critique which can lead to reflection on the concept being translated regardless if it's revering to the &quot;original&quot; concept or the newly installed digital one. And right now, when we talk about &quot;digitization&quot;, is the moment to work on this before we're unable to distinguish between the implementation and the practice itself and the translation becomes the replacing instance.
			- When we criticise <em>Facebook</em>, we can think about <em>friendship</em> and <em>social interactions</em>.
			- When we criticise <em>Twitter</em>, we can think about how we get our <em>news</em>.
			- When we criticise <em>Google</em>, we can think about <em>knowledge</em>.</p>

			<h2>About</h2>

			<p>In the beginning, this essay was written by <a href="https://fernando-obieta.com" target="_blank">Fernando Obieta</a> in his second Semester at the <a href="https://zhdk.ch" target="_blank">Zurich University of the Arts</a> enrolled in the masters program <a href="https://www.zhdk.ch/en/degree-programmes/transdisciplinary-studies-73/transdisciplinarystudies" target="_blank">&quot;Transdisciplinary Studies in the Arts&quot;</a>. Special Thanks to: <a href="https://www.zhdk.ch/person/7848" target="_blank">Prof. Irene Vögeli</a>, <a href="https://www.zhdk.ch/person/11115" target="_blank">Basil Rogger</a>, <a href="https://jilsanchez.com/" target="_blank">Jil Sanchez</a> and Marco Wettach.</p>

			<h2>The digital space</h2>

			<figure>
			<img src="https://images-na.ssl-images-amazon.com/images/I/51K5MWCVQAL._SX258_BO1,204,203,200_.jpg" alt="" />
			</figure>

			<p>When we think about &quot;space&quot; we most commonly use it in two contexts: a physically existing space located in the world or a metaphorical one which often refers to time. I argue, that the digital space is like no other we have encountered before, because when you compare it, it doesn't behave like other spaces, encapsulated within themselves, but penetrates nearly all other spaces in our physical world. It acts like an additional layer within and spanning across, which can also be understood as an additional layer of society.
			In 1967, Michel Foucault described his concept of <a href="https://en.wikipedia.org/wiki/Heterotopia_(space)" target="_blank">Heterotopia</a> like the following:</p>

			<blockquote>
			<p>&quot;There are also, probably in every culture, in every civilization, real places—places that do exist and that are formed in the very founding of society—which are something like counter-sites, a kind of effectively enacted utopia in which the real sites, all the other real sites that can be found within the culture, are simultaneously represented, contested, and inverted. Places of this kind are outside of all places, even though it may be possible to indicate their location in reality. Because these places are absolutely different from all the sites that they reflect and speak about, I shall call them, by way of contrast to utopias, heterotopias.&quot;<br/>
			 <em>Michel Foucault 1967</em><sup><a href="#fn5-1593" id="fnr5-1593" title="see footnote" className="footnote">5</a></sup></p>
			</blockquote>

			<figure>
			<img src="https://attheirmajestiespleasure.files.wordpress.com/2017/10/974ea86fa12182de84b24575d77f609d-foucault-michel-philosophers.jpg" alt="" />
			</figure>

			<p>The description Foucault provided seems to be fitting to a romantic description of the internet over forty years before it became part of our everyday life. One could argue, that the internet isn't &quot;real&quot; and only exists in a form of interpretation and translation an isn't bound to a physical space<sup><a href="#fn6-1593" id="fnr6-1593" title="see footnote" className="footnote">6</a></sup> like ships or brothels as Foucault describes his concept. They way that people and the media refer to the &quot;digital space&quot; reveals an underlying misapprehension that we could escape or ignore this space.</p>

			<blockquote>
			<p>&quot;Heterotopias always presuppose a system of opening and closing that both isolates them and makes them penetrable. In general, the heterotopic site is not freely accessible like a public place. Either the entry is compulsory, as in the case of entering a barracks or a prison, or else the individual has to submit to rites and purifications. To get in one must have a certain permission and make certain gestures. [...]&quot;
			<br/>
			<em>Michel Foucault 1967</em><sup><a href="#fn7-1593" id="fnr7-1593" title="see footnote" className="footnote">7</a></sup></p>
			</blockquote>

			<p>The submission to these new forms of communication is becoming a requirement to stay relevant within society, with even jobs requiring digital application in fields which don't need this specific skillset in their practice. To a certain extend, the ability to navigate through the digital forms of communication and interaction became the new center piece our education is concerned and struggling with to give people the means to comprehend our world. But this tends towards the usage and not the understanding or reflections of these &quot;tools&quot;. If we follow the submission we're actively dividing our society into &quot;users of technology&quot; and &quot;absentees&quot;. The threshold that one has to overcome to communicate with someone for longer then just a few interactions in person <strong>without</strong> – for example – a smartphone<sup><a href="#fn8-1593" id="fnr8-1593" title="see footnote" className="footnote">8</a></sup> and availability through instant messaging or e-mail, is larger in comparison than with someone who's using these tools like you right now. Maybe we're constantly peer-pressuring – without specifically intending to do so – other people to join our digital heterotopia of efficiency<sup><a href="#fn9-1593" id="fnr9-1593" title="see footnote" className="footnote">9</a></sup>.<br/>
			So maybe, the compulsory &quot;feeling&quot; that arises, that you're &quot;missing out&quot; when you're not part of this digital &quot;revolution&quot;, forces people to define a position towards this digital space. I argue, that the individual choice one makes isn't the interesting thing, but the nature of our time that it become part of our everyday discourse that one has to <em>make</em> a choice how one stands to the digital space.<br/>
			Do you have <em>Facebook, Instagram, GMail, Skype, WhatsApp, Twitter, Telegram, Signal, Threema, YouTube, Netflix, HBO, Spotify, Apple Music, Dropbox, Reddit</em>... why not? It's so useful!<br/>
			- Have you seen my <em>Instagram Story</em>?<br/>
			- Have you seen what Elon Musk posted on <em>Twitter</em> this morning?<br/>
			- Are you coming to the party I've invited you to on <em>Facebook</em>?<br/>
			- Did you watch the newest episode of &quot;Game of Thrones&quot; on <em>HBO</em>?<br/>
			- Did you read my text about your assignment next week on <em>WhatsApp</em>?</p>

			<p>Our private and social lives are more intertwined than ever before with these tools. They're telling us, that you're relevant and part of society if you're using them; if you're following the people you admire and know; if you're showing the world who you actually are; if you're telling your story; and all of this not just inside an external isolated space with its own rules, but within a layer entangled with society and our everyday lives, abstracted from our past, present and – through absorption – also future concepts of interactions with each other. </p>

			<h2>From a system to a system</h2>

			<p>The translation of man made concepts and system into a computer system requires the hard choice of determining what an analogue value is into a digital one. 1s and 0s. Not every system we have in place is able to be abstracted in such a form, and even though a few of them are, are the problems of man made system of responsibility and agency even in seemingly easy examples hard to put down:</p>
			<div className="embed-container"><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/w3_0x6oaDmI?rel=0" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"></iframe></div>

			<p><em>Tom Scott, 2014</em><sup><a href="#fn10-1593" id="fnr10-1593" title="see footnote" className="footnote">10</a></sup></p>

			<p>If we can bring it in a digital form, with the promise of &quot;better&quot; integration for the people using it, why shouldn't we do it? The pretense might be even a noble one, but the impact and consequences might be unforeseeable, especially with something as delicate like human interaction. The example above about voting mechanisms illustrates that even man made systems of representation and responsibility like the simple &quot;yes&quot; or &quot;no&quot; to a question posed by a government to its citizens is practically impossible without creating new forms of exploitation.
			I argue, that it isn't solely about the shift in agency but also about the shift of responsibility from people with the knowledge of the context to programmers.</p>

			<blockquote>
			<p>&quot;I will say something about why to invent as well. Because you could see our work as experimental, or science fiction, or futuristic; but I would say - and others in the studio may not agree with me - that our design is essentially a political act. We design 'normative' products, normative being that you design for the world as it should be. Invention is always for the world as it should be, and not for the world you are in.<br/>
			By designing it, it's a bit like the way the earth attracts the moon, and the moon attracts the earth just a tiny bit. Design these products and you'll move the world just slightly in that direction.&quot;<br/>
			<em>Matt Webb, 2012</em><sup><a href="#fn11-1593" id="fnr11-1593" title="see footnote" className="footnote">11</a></sup></p>
			</blockquote>

			<p>Webb talks about designers here, but I think the comparison to programmers isn't far fetched, as the two professions deal with the same problem at hand, abstraction and translation into something people without the required knowledge <em>could</em> understand to use. So the question becomes rather than just a practical one of <em>how</em> you can convey the necessary information also one of ethics and one of how <em>should</em> you convey the information. Each and every designed artefact isn't a &quot;objective&quot; representation of <em>what is needed</em> but the subjective understanding of its creators. </p>

			<blockquote>
			<p>&quot;We are quite willing to admit that technology is the extension of our organs. We knew it was the reduction of force. We had simply forgotten that it was also the delegation of our morality. The missing mass is before our eyes, everywhere present, in what we admiringly or scornfully call the world of efficiency and function. Do we lack morality in our technological societies? Not at all. Not only have we recuperated the mass that we lacked to complete our sum, but we can see that we are infinitely more moral than our predecessors.&quot;<br/>
			<em>Bruno Latour, 1989</em><sup><a href="#fn12-1593" id="fnr12-1593" title="see footnote" className="footnote">12</a></sup></p>
			</blockquote>

			<p>By relocating the morality out of the individual into an artefact pushes the user of the artefact to follow the morality. The specific morality and its orientation isn't chosen by the user anymore but the creators of the artefact. This way of thinking – organising morality, efficiency and risk – was the dream of <a href="https://en.wikipedia.org/wiki/Cybernetics" target="_blank">cybernetics</a> and <a href="https://en.wikipedia.org/wiki/Systems_theory" target="_blank">system-theorists</a>. An overspanning all including system which regulates all of its components with feedback-loops:</p>
			<div className="embed-container"><iframe src="https://player.vimeo.com/video/300725472#t=28m" width="640" height="358" frameBorder="0" allow="autoplay; fullscreen"></iframe></div>

			<p><em>Adam Curtis, 2011</em>, 28:00 – 36:05<sup><a href="#fn13-1593" id="fnr13-1593" title="see footnote" className="footnote">13</a></sup></p>

			<p>The level of complexity far overreaches the capacity of our understanding of how society and nature operate. But the believe in this vision, of a model to regulate and comprehend the world we're in lead to a &quot;trust&quot; in machines, which they will never be able to fulfill. A machine or system can never exceed its creators in their vision, only in efficiency, and this efficiency only scales the subjective understanding its creators have put into it and can't eradicate it<sup><a href="#fn14-1593" id="fnr14-1593" title="see footnote" className="footnote">14</a></sup>. But this mislead trust in these &quot;neutral&quot; and &quot;objective&quot; machines averts us from the fact that they will never be able to &quot;solve&quot; our social challenges which we'll have to carry out ourselves now and in the future and these biased machines can only be what they were before: a tool or an enhancement:</p>

			<blockquote>
			<p>&quot;Now, it might be that in any technological utopia which we have any real chance of creating, all individuals will remain constrained in important ways. In addition to the challenges of the physical frontiers, which might at this stage be receding into deep space as the posthuman civilization expands beyond its native planet, there are the challenges created by the existence of other posthumans, that is, the challenges of the social realm. Resources even in Plastic World would soon become scarce if population growth is exponential, but aside from material constraints, individual agents would face the constraints imposed on them by the choices and actions of other agents. Insofar as our goals are irreducibly social – for example to be loved, respected, given special attention or admiration, or to be allowed to spend time or to form exclusive bonds with the people we choose, or to have a say in what other people do – we would still be limited in our ability to achieve our goals. Thus, a being in Plastic World may be very far from omnipotent. Nevertheless, we may suppose that a large portion of the constraints we currently face have been lifted and that both our internal states and the world around us have become much more malleable to our wishes and desires.&quot;<br/>
			<em>Nick Bostrom, 2007</em><sup><a href="#fn15-1593" id="fnr15-1593" title="see footnote" className="footnote">15</a></sup></p>
			</blockquote>

			<p>Maybe we're just following our system of hearing what we want to hear and just created a new word with the &quot;filter-bubble&quot; to get rid of the responsibility.</p>

			<h2>Progress</h2>

			<figure>
			<img src="https://imgs.xkcd.com/comics/wikipedian_protester.png" alt="" />
			</figure>

			<p>It can be argued, that the human &quot;need&quot; to receive, transfer and share information as a survival mechanism found its logical continuation in the internet. The efficient transfer from speech, to text in its physical form to a fluid accessible digital form divided in bits and bytes delivered to our screens is a causality follow by an ideology of constant progress as a society and species. But now the question arises what &quot;progress&quot; actually is: </p>
			<div className="embed-container"><iframe src="https://player.vimeo.com/video/191817381#t=23m26s" width="640" height="358" frameBorder="0" allow="autoplay; fullscreen"></iframe></div><br/>
			<em>Adam Curtis, 2016</em>, 23:26 – 26:55<sup><a href="#fn16-1593" id="fnr16-1593" title="see footnote" className="footnote">16</a></sup>

			<p>When we apply the same logic Arkady and Boris Strugatsky coined with &quot;HyperNormalisation&quot; in <a href="https://en.wikipedia.org/wiki/Roadside_Picnic" target="_blank">Roadside Picnic</a> as depicted in Adam Curtis documentary with the same name, to our digital age, we can start to ask the question of how much of this is &quot;progress&quot; and what is just a more efficient way of implementing our concepts. I argue, that a lot of our interpersonal problems that arose the last decade are based in a lack of progress in our sociological concepts of communication. Of course we have <a href="https://en.wikipedia.org/wiki/Emoji" target="_blank">Emojis</a> now to better convey what we really mean, but the basis stayed the same. Our ways of communication where never meant for an efficiency of this magnitude.
			- I wrote you a text on <em>WhatsApp</em> 15' ago. <a href="http://www.bbc.co.uk/newsbeat/article/29933261/blue-ticks-on-whatsapp-what-they-really-mean" target="_blank">I saw that you've read it</a> but you didn't reply!
			- 23:20 on a Sunday: Here's the assignment. Done by tomorrow at noon.
			- I saw that you're friends now with Laura on <em>Facebook</em>. You know I hate her!</p>

			<p>Maybe we're just pretending that these forms of communication are &quot;better&quot; or &quot;progress&quot;. They seem to make us more efficient but everything is also trying to get our attention and must be dealt with immediately. But if this thesis is true, why are we pretending? The only possibility I can think of is an empowered drive for validation and looking for the &quot;best possible solution&quot; for ourself as in an evolutionary drive.</p>

			<p>In his book &quot;The Insanity of Normality&quot; the psychologist and psychoanalyst <a href="https://en.wikipedia.org/wiki/Arno_Gruen" target="_blank">Arno Gruen</a> is looking for a reasoning for this way of behaviour and describes the empathatic nature of &quot;wanting to be loved&quot; and &quot;wants to love others&quot; in exchange of autonomy. We like to be guided towards these feelings and don't tend to reflect the means of how we achieve them in the process as long as they fulfil our desires. In this regard is the shift towards these new forms of communication almost logical with their quick fixes of affirmation.</p>

			<h2>Who is my avatar</h2>

			<figure>
			<img src="https://cnet3.cbsistatic.com/img/AaRfnI37JQsXHrYnzCyBhaeWLJc=/1600x900/2018/05/01/ff1f9057-477c-49cc-a737-227a52d707de/facebook-f8-2018-0288.jpg" alt="" />
			</figure>

			<p>Various science fiction writers described utopian or dystopian worlds in which the society in it is deprived of reflection on their guiding systems. Like in &quot;Brave new world&quot;<sup><a href="#fn17-1593" id="fnr17-1593" title="see footnote" className="footnote">17</a></sup> by Aldous Huxley in which the actors of a society are pressuring each other to take the happiness-producing drug &quot;soma&quot;. When you compare this drug to the pressure of availability and representation on social media platforms like Facebook and Instagram on which everyone is happy, everyone is successful and everyone is doing great things in their individual lives, we're practically already doing the same thing. We force upon our individual selves the pressure of capitalization and quantification of each and every aspect of our lives, to show our peers that we're worth the &quot;social capital&quot; that we represent. But the dissonance between our presented selves and how – we think – we are is an age old discussion in sociology and psychology also along the line of how we perceive ourselves. Social media gives us the means to do this in an orderly and structured fashion. You have the same amount of space like everyone else to fill up with as many of things that you see fit to &quot;correctly&quot; show us who you actually are – or you would like us to believe who you are.</p>

			<p>In his book &quot;Alienation and Acceleration&quot;<sup><a href="#fn18-1593" id="fnr18-1593" title="see footnote" className="footnote">18</a></sup>, Hartmut Rosa argues that the promise of the moderne era is the autonomy to decide – individually and collectively – what self-determination is. <em>Who we are</em> and <em>how we want to live</em>. But this aim toward autonomy is clouded by the rising alienation and acceleration (the title of his book) we developed along side. He further describes this situation as a &quot;competitive-society&quot;, in which the highest aim is to be happier than your peers, in which the sole move is to like and not to reflect, and the end justifies the means and one superlative overthrows the next one. And in this situation, who you're can't always be represented in a system in which the only reaction a &quot;like&quot; is and the separation of who you're online and in the physical world becomes inevitable.</p>

			<p>We've created a perfect new world of discipline through each other and these tools. Everyone stays in their lane and who doesn't isn't part of our modern world. So, your only option is self-control as Gilles Deleuze describes in a further development of Michel Foucaults thoughts on power and control:</p>

			<blockquote>
			<p>&quot;The socio-technological study of the mechanisms of control, grasped at their inception, would have to be categorical and to describe what is already in the process of substitution for the disciplinary sites of enclosure, whose crisis is everywhere proclaimed. lt may be that older methods, borrowed from the former societies of sovereignty, will return to the fore, but with the necessary modifications. What counts is that we are at the beginning of something.&quot;<br/>
			[...]<br/>
			&quot;Can we already grasp the rough outlines of these coming forms, capable of threatening the joys of marketing? Many young people strangely boast of being &quot;motivated&quot;; they re-request apprenticeships and permanent training. It's up to them to discover what they're being made to serve, just as their elders discovered, not without difficulty, the telos of the disciplines. The coils of a serpent are even more complex than the burrows of a molehill.&quot;<br/>
			<em>Gilles Deleuze, 1992</em><sup><a href="#fn19-1593" id="fnr19-1593" title="see footnote" className="footnote">19</a></sup></p>
			</blockquote>

			<p>And we're discovering at first hand what our &quot;marketing of the self&quot; is creating. A society in permanent dependency to reactions through arbitrary feedback which isn't able to replace inter-human-interaction.</p>

			<blockquote>
			<p>Any gesture of refusal short of going off the grid entirely will be still less likely to result in the desired independence from the process of intimate, persistent oversight and management now loose in the world. Just as whatever degree of freedom to act we enjoy is already sharply undercut by commercial pressures, and the choices made in aggregate by others, so too will our scope of action be constrained by the shape of the place that is left for us by the functioning of automated and algorithmic systems, the new shape of the natural, the ordinary and the obvious – for that is ho hegemony works. If neoliberalism, like any hegemonic system, produced subjects with characteristic affects, desires, values, instincts and modes of expression, and those subjects came in time to constitute virtually the entirety of the social environment any of us experience, it's hard to see how matters could be any different in the wake of the posthuman turn. It is exceedingly hard to outright refuse something which has become part of you – and made you part of it – in the most literal way, right down to the molecular composition of your body and the content of your dreams.<br/>
			<em>Adam Greenfield, 2017</em><sup><a href="#fn20-1593" id="fnr20-1593" title="see footnote" className="footnote">20</a></sup></p>
			</blockquote>

			<p>But don't be afraid. If you come back, your avatar will still be here.</p>

			<div className="footnotes">
			<hr />
			<ol>

			<li id="fn1-1593">
			<p>which is – when this project works in the intended way – now and in the future <a href="#fnr1-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn2-1593">
			<p>In my case right now: the German speaking part of Switzerland in April 2019 <a href="#fnr2-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn3-1593">
			<p>like the <a href="https://en.wikipedia.org/wiki/Cambridge_Analytica" target="_blank">Facebook–Cambridge Analytica data scandal 2018</a>, the leaks surrounding <a href="https://en.wikipedia.org/wiki/Global_surveillance_disclosures_(2013%E2%80%93present)" target="_blank">surveilance</a> which are on an all time high since the <a href="https://en.wikipedia.org/wiki/Edward_Snowden#Global_surveillance_disclosures" target="_blank">Snowden leaks in 2013</a>, the list is long... <a href="#fnr3-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn4-1593">
			<p>a <a href="https://en.wikipedia.org/wiki/Version_control" target="_blank">version control system</a> used and misused by programmers all over the world for sharing and collaborating on a variety of code based projects <a href="#fnr4-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn5-1593">
			<p><a href="http://web.mit.edu/allanmc/www/foucault1.pdf" target="_blank">Michel Foucault, 1967. <em>Of Other Spaces: Utopias and Heterotopias</em></a>, from <em>Architecture / Mouvement / Continuité</em>, October, 1984;(“Des Espace Autres,” March 1967 Translated from the French by Jay Miskowiec), p. 3-4 <a href="#fnr5-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn6-1593">
			<p>at least, not anymore since the era of the &quot;internet cafes&quot; died in the early 2000s <a href="#fnr6-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn7-1593">
			<p><a href="http://web.mit.edu/allanmc/www/foucault1.pdf" target="_blank">Michel Foucault, 1967. <em>Of Other Spaces: Utopias and Heterotopias</em></a>, from <em>Architecture / Mouvement / Continuité</em>, 1984; (“Des Espace Autres,” March 1967 Translated from the French by Jay Miskowiec), p. 7 <a href="#fnr7-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn8-1593">
			<p>this is going to be crucial to update in the future! Who knows when the next thing will take over... <a href="#fnr8-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn9-1593">
			<p>The fact that you're reading this right now on a website, in a browser, on a device (like a computer or a smartphone) implies that you're at least to a certain extend part of this <a href="#fnr9-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn10-1593">
			<p><a href="https://youtu.be/w3_0x6oaDmI" target="_blank">Computerphile, Tom Scott, 2014. <em>Why Electronic Voting is a BAD Idea</em>, YouTube</a> <a href="#fnr10-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn11-1593">
			<p>Matt Webb, 2012. <em>The near future inventor</em> in: <a href="https://roryhyde.com/Future-Practice" target="_blank">Rory Hyde, <em>Future Practice: Conversations from the Edge of Architecture</em></a>, New York: Routledge, 2012 <a href="#fnr11-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn12-1593">
			<p><a href="https://courses.ischool.berkeley.edu/i290-tpl/s11/w/images/6/69/The_Moral_Dilemmas_of_a_Safety-belt.pdf" target="_blank">Bruno Latour, 1989. <em>The Moral Dilemmas of a Safety-belt</em> from: La Ceinture de sécurité”, in Alliage N°1 p.21-27. Traduction inédite en anglais, unpublished English translation by Lydia Davis</a>, p. 6 <a href="#fnr12-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn13-1593">
			<p><a href="https://vimeo.com/300725472" target="_blank">Adam Curtis, 2016. <em>All Watched Over by Machines of Loving Grace - Episode 2 - The Use and Abuse of Vegetational Concepts</em>, BBC</a>, 28:00 – 36:05 <a href="#fnr13-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn14-1593">
			<p>Like the many times programs operated by <a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank">&quot;machine learning&quot;</a> – to which people often falsely refer to as <a href="https://en.wikipedia.org/wiki/Artificial_intelligence" target="_blank">&quot;A.I.&quot;</a> – created <a href="https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist" target="_blank">racist</a> or <a href="https://www.technologyreview.com/s/612876/this-is-how-ai-bias-really-happensand-why-its-so-hard-to-fix/" target="_blank">biased</a> outcomes <a href="#fnr14-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn15-1593">
			<p><a href="https://nickbostrom.com/ethics/dignity-enhancement.pdf" target="_blank">Nick Bostrom, 2007. <em>Dignity and Enhancement</em></a>, p. 30 <a href="#fnr15-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn16-1593">
			<p><a href="https://vimeo.com/191817381" target="_blank">Adam Curtis, 2016. <em>HyperNormalisation</em>, BBC</a>, 23:26 – 26:55 <a href="#fnr16-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn17-1593">
			<p>Huxley, Aldous, 1931. <em>Brave new world</em>, New York: Everyman's Library. <a href="#fnr17-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn18-1593">
			<p>Hartmut Rosa, 2010. <em>Alienation and Acceleration: Towards a Critical Theory of Late-Modern Temporality</em>, Aarhus University Press <a href="#fnr18-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn19-1593">
			<p>Gilles Deleuze, 1992. <a href="https://cidadeinseguranca.files.wordpress.com/2012/02/deleuze_control.pdf" target="_blank"><em>Postscript on the Societies of Control</em></a>, MIT-Press, p. 7 <a href="#fnr19-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn20-1593">
			<p><a href="https://en.wikipedia.org/wiki/Radical_Technologies" target="_blank">Adam Greenfield, 2018. <em>Radical technologies : the design of everyday life</em></a> London: Verso., p. 310-311 <a href="#fnr20-1593" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			</ol>
			</div>
			</article>
			);
}

}