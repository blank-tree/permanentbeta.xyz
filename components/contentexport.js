// this is a situational fix for the presentation on 12.04.2019, but not the solution for the import (yet)
// we're currently using the "iA Writer" HTML export here

import React, {Component} from 'react';

export default class Export extends Component {

	render() {
		return(
			<article>
			<h2>Introduction</h2>

			<p>This is a text on the internet. There are many like it but this one is mine;<br/>
			and yours;<br/>
			and everyones;<br/>
			ever changing;<br/>
			never finished.</p>

			<p>I'm going on an adventure by my own choosing, to think and write about the landscape we're currently<sup><a href="#fn1-13914" id="fnr1-13914" title="see footnote" className="footnote">1</a></sup> in and the changes to our collective way of thinking about ourselves and the society<sup><a href="#fn2-13914" id="fnr2-13914" title="see footnote" className="footnote">2</a></sup> we're part of.
			Thinking back, the last two decades marked a drastically shift in the ways individuals and groups communicate with each other in a modern world. The expectation that everyone around us knows how to use (and misuse) the new tools of communication and information seem to unearth the ambiguity of the underlying concepts. With the implementation of this ambiguity into fixed systems – built mostly by private companies – our society also seems to lose the agency to advance them themselves in the future. This is a pessimistic view of <a href="https://en.wikipedia.org/wiki/Digitization">digitization</a> and falls in line with the way of thinking of the <a href="https://en.wikipedia.org/wiki/Swing_Riots">Swing Riots in the 1830s</a>. One could think with the rhetoric used in news articles<sup><a href="#fn3-13914" id="fnr3-13914" title="see footnote" className="footnote">3</a></sup> discussing pitfalls and setbacks – from the point of view of companies working in these fields – that an <a href="https://en.wikipedia.org/wiki/Orwellian">&quot;Orwellian Dystopia&quot;</a> is the only logical outcome. A worrying outlook, but in my humble opinion is this not the entire story and much of it is still in our – individual and collective – hands.<br/>
			Maybe these changes we're all currently experiencing give us an opportunity not just to reflect the new implementations of everyday interactions, but also to reflect the interactions and concepts they're based on. Grand shifts in society tended to discuss specific variables and rarely society in its entirety, but that is exactly what we're currently undergoing when we try to translate more and more aspects and interactions into the digital realm under the flag of efficiency, and the result is a deadening and confusion amongst our peers and ourselves.</p>

			<p>This essay doesn't only give a highly subjective and opinionated view of the matters at hand, but also challenge the reader with a few obstacles along the way. The structure isn't fixed, the conclusions and views are ever shifting – even while you're currently reading this –, and over time, there will be additional changes I and hopefully other will supply to this essay. You can follow and judge the progression of this construct on the <a href="https://github.com/blank-tree/permanentbeta.xyz">Git-Repository</a><sup><a href="#fn4-13914" id="fnr4-13914" title="see footnote" className="footnote">4</a></sup> or more specifically in the <a href="https://github.com/blank-tree/permanentbeta.xyz/commits/master">commit history</a>.</p>

			<p>Because of the previously described nature of this essay, I'm already providing my conclusion of the following paragraphs: Dividing opinions regarding the internet in dystopian or utopian camps misses the opportunity to think of something in between: The act of the translation into the digital realm itself. This act – combined with the fact that any practice of abstraction and/or translation has to deal with a certain amount of loss of information – offers a working surface to place critique which can lead to reflection on the concept being translated regardless if it's revering to the &quot;original&quot; concept or the newly installed digital one. And right now, when we talk about &quot;digitization&quot;, is the moment to work on this before we're unable to distinguish between the implementation and the practice itself and the translation becomes the replacing instance.</p>

			<h2>About</h2>

			<p>In the beginning, this essay was written by <a href="https://fernando-obieta.com">Fernando Obieta</a> in his second Semester at the <a href="https://zhdk.ch">Zurich University of the Arts</a> enrolled in the masters program <a href="https://www.zhdk.ch/en/degree-programmes/transdisciplinary-studies-73/transdisciplinarystudies">&quot;Transdisciplinary Studies in the Arts&quot;</a>. Thanks goes to: <a href="https://www.zhdk.ch/person/7848">Prof. Irene Vögeli</a>, <a href="https://www.zhdk.ch/person/11115">Basil Rogger</a>, <a href="https://jilsanchez.com/">Jil Sanchez</a> and Marco Wettach.</p>

			<h2>The digital space</h2>

			<figure>
			<img src="https://images-na.ssl-images-amazon.com/images/I/51K5MWCVQAL._SX258_BO1,204,203,200_.jpg" alt="" />
			</figure>

			<p>When we think about &quot;space&quot; we most commonly use it in two contexts: a physically existing space located in the world or a metaphorical one which often refers to time. I argue, that the digital space is like no other we have encountered before, because when you compare it, it doesn't behave like other spaces, encapsulated within themselves, but penetrates nearly all other spaces in our physical world. It acts like an additional layer within and spanning across, which can also be understood as an additional layer of society.
			In 1967, Michel Foucault described his concept of <a href="https://en.wikipedia.org/wiki/Heterotopia_(space)">Heterotopia</a> like the following:</p>

			<blockquote>
			<p>&quot;There are also, probably in every culture, in every civilization, real places—places that do exist and that are formed in the very founding of society—which are something like counter-sites, a kind of effectively enacted utopia in which the real sites, all the other real sites that can be found within the culture, are simultaneously represented, contested, and inverted. Places of this kind are outside of all places, even though it may be possible to indicate their location in reality. Because these places are absolutely different from all the sites that they reflect and speak about, I shall call them, by way of contrast to utopias, heterotopias.&quot;<br/>
			 <em>Michel Foucault 1967</em><sup><a href="#fn5-13914" id="fnr5-13914" title="see footnote" className="footnote">5</a></sup></p>
			</blockquote>

			<figure>
			<img src="https://attheirmajestiespleasure.files.wordpress.com/2017/10/974ea86fa12182de84b24575d77f609d-foucault-michel-philosophers.jpg" alt="" />
			</figure>

			<p>The description Foucault provided seems to be fitting to a romantic description of the internet over forty years before it became part of our everyday life. One could argue, that the internet isn't &quot;real&quot; and only exists in a form of interpretation and translation an isn't bound to a physical space<sup><a href="#fn6-13914" id="fnr6-13914" title="see footnote" className="footnote">6</a></sup> like ships or brothels as Foucault describes his concept. They way that people and the media refer to the &quot;digital space&quot; reveals an underlying misapprehension that we could escape or ignore this space.</p>

			<blockquote>
			<p>&quot;Heterotopias always presuppose a system of opening and closing that both isolates them and makes them penetrable. In general, the heterotopic site is not freely accessible like a public place. Either the entry is compulsory, as in the case of entering a barracks or a prison, or else the individual has to submit to rites and purifications. To get in one must have a certain permission and make certain gestures. [...]&quot;
			<br/>
			<em>Michel Foucault 1967</em><sup><a href="#fn7-13914" id="fnr7-13914" title="see footnote" className="footnote">7</a></sup></p>
			</blockquote>

			<p>The submission to these new forms of communication is becoming a requirement to stay relevant within society, with even jobs requiring digital application in fields which don't need this specific skillset in their practice. To a certain extend, the ability to navigate through the digital forms of communication and interaction became the new center piece our education is concerned and struggling with to give people the means to comprehend our world. But this tends towards the usage and not the understanding or reflections of these &quot;tools&quot;. If we follow the submission we're actively dividing our society into &quot;users of technology&quot; and &quot;absentees&quot;. The threshold that one has to overcome to communicate with someone for longer then just a few interactions in person <strong>without</strong> – for example – a smartphone<sup><a href="#fn8-13914" id="fnr8-13914" title="see footnote" className="footnote">8</a></sup> and availability through instant messaging or e-mail, is larger in comparison than with someone who's using these tools like you right now. Maybe we're constantly peer-pressuring – without specifically intending to do so – other people to join our digital heterotopia of efficiency<sup><a href="#fn9-13914" id="fnr9-13914" title="see footnote" className="footnote">9</a></sup>.<br/>
			So maybe, the compulsory &quot;feeling&quot; that arises, that you're &quot;missing out&quot; when you're not part of this digital &quot;revolution&quot;, forces people to define a position towards this digital space. I argue, that the individual choice one makes isn't the interesting thing, but the nature of our time that it become part of our everyday discourse that one has to <em>make</em> a choice how one stands to the digital space.<br/>
			Do you have <em>Facebook, Instagram, GMail, Skype, WhatsApp, Twitter, Telegram, Signal, Threema, YouTube, Netflix, HBO, Spotify, Apple Music, Dropbox, Reddit</em>... why not? It's so useful!<br/>
			Have you seen my <em>Instagram Story</em>?<br/>
			Have you seen what Elon Musk posted on <em>Twitter</em> this morning?<br/>
			Are you coming to the party I've invited you to on <em>Facebook</em>?<br/>
			Did you watch the newest episode of &quot;Game of Thrones&quot; on <em>HBO</em>?<br/>
			Did you read my text about your assignment next week on <em>WhatsApp</em>?</p>

			<p>Our private and social lives are more intertwined than ever before with these tools. They're telling us, that you're relevant and part of society if you're using them; if you're following the people you admire and know; if you're showing the world who you actually are; if you're telling your story; and all of this not just inside an external isolated space with its own rules, but within a layer entangled with society and our everyday lives, abstracted from our past, present and – through absorption – also future concepts of interactions with each other. </p>

			<h2>From a system to a system</h2>

			<p>The translation of man made concepts and system into a computer system requires the hard choice of determining what an analogue value is into a digital one. 1s and 0s. Not every system we have in place is able to be abstracted in such a form, and even though a few of them are, are the problems of man made system of responsibility and agency even in seemingly easy examples hard to put down:</p>
			<div className="embed-container"><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/w3_0x6oaDmI?rel=0" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"></iframe></div>

			<p><em>Tom Scott, 2014</em><sup><a href="#fn10-13914" id="fnr10-13914" title="see footnote" className="footnote">10</a></sup></p>

			<p>If we can bring it in a digital form, with the promise of &quot;better&quot; integration for the people using it, why shouldn't we do it? The pretense might be even a noble one, but the impact and consequences might be unforeseeable, especially with something as delicate like human interaction. The example above about voting mechanisms illustrates that even man made systems of representation and responsibility like the simple &quot;yes&quot; or &quot;no&quot; to a question posed by a government to its citizens is practically impossible without creating new forms of exploitation.
			I argue, that it isn't solely about the shift in agency but also about the shift of responsibility from people with the knowledge of the context to programmers.</p>

			<blockquote>
			<p>&quot;I will say something about why to invent as well. Because you could see our work as experimental, or science fiction, or futuristic; but I would say - and others in the studio may not agree with me - that our design is essentially a political act. We design 'normative' products, normative being that you design for the world as it should be. Invention is always for the world as it should be, and not for the world you are in.<br/>
			By designing it, it's a bit like the way the earth attracts the moon, and the moon attracts the earth just a tiny bit. Design these products and you'll move the world just slightly in that direction.&quot;<br/>
			<em>Matt Webb, 2012</em><sup><a href="#fn11-13914" id="fnr11-13914" title="see footnote" className="footnote">11</a></sup></p>
			</blockquote>

			<p>Webb talks about designers here, but I think the comparison to programmers isn't far fetched, as the two professions deal with the same problem at hand, abstraction and translation into something people without the required knowledge <em>could</em> understand to use. So the question becomes rather than just a practical one of <em>how</em> you can convey the necessary information also one of ethics and one of how <em>should</em> you convey the information. Each and every designed artefact isn't a &quot;objective&quot; representation of <em>what is needed</em> but the subjective understanding of its creators. </p>

			<blockquote>
			<p>&quot;We are quite willing to admit that technology is the extension of our organs. We knew it was the reduction of force. We had simply forgotten that it was also the delegation of our morality. The missing mass is before our eyes, everywhere present, in what we admiringly or scornfully call the world of efficiency and function. Do we lack morality in our technological societies? Not at all. Not only have we recuperated the mass that we lacked to complete our sum, but we can see that we are infinitely more moral than our predecessors.&quot;<br/>
			<em>Bruno Latour, 1989</em><sup><a href="#fn12-13914" id="fnr12-13914" title="see footnote" className="footnote">12</a></sup></p>
			</blockquote>

			<p>By relocating the morality out of the individual into an artefact pushes the user of the artefact to follow the morality. The specific morality and its orientation isn't chosen by the user anymore but the creators of the artefact. This way of thinking – organising morality, efficiency and risk – was the dream of cybernetics and system-theorists. An overspanning all including system which regulates all of its components with feedback-loops:</p>
			<div className="embed-container"><iframe src="https://player.vimeo.com/video/300725472#t=28m" width="640" height="358" frameborder="0" allow="autoplay; fullscreen"></iframe></div>

			<p><em>Adam Curtis, 2011</em>, 28:00 – 36:05<sup><a href="#fn13-13914" id="fnr13-13914" title="see footnote" className="footnote">13</a></sup></p>

			<p>The level of complexity far overreaches the capacity of our understanding of how society and nature operate. But the believe in this vision, of a model to regulate and comprehend the world we're in lead to a &quot;trust&quot; in machines, which they will never be able to fulfill. A machine or system can never exceed its creators in their vision, only in efficiency, and this efficiency only scales the subjective understanding its creators have put into it and can't eradicate it<sup><a href="#fn14-13914" id="fnr14-13914" title="see footnote" className="footnote">14</a></sup>. But this mislead trust in these &quot;neutral&quot; and &quot;objective&quot; machines averts us from the fact that they will never be able to &quot;solve&quot; our social challenges which we'll have to carry out ourselves now and in the future and these biased machines can only be what they were before: a tool or an enhancement:</p>

			<blockquote>
			<p>&quot;Now, it might be that in any technological utopia which we have any real chance of creating, all individuals will remain constrained in important ways. In addition to the challenges of the physical frontiers, which might at this stage be receding into deep space as the posthuman civilization expands beyond its native planet, there are the challenges created by the existence of other posthumans, that is, the challenges of the social realm. Resources even in Plastic World would soon become scarce if population growth is exponential, but aside from material constraints, individual agents would face the constraints imposed on them by the choices and actions of other agents. Insofar as our goals are irreducibly social – for example to be loved, respected, given special attention or admiration, or to be allowed to spend time or to form exclusive bonds with the people we choose, or to have a say in what other people do – we would still be limited in our ability to achieve our goals. Thus, a being in Plastic World may be very far from omnipotent. Nevertheless, we may suppose that a large portion of the constraints we currently face have been lifted and that both our internal states and the world around us have become much more malleable to our wishes and desires.&quot;<br/>
			<em>Nick Bostrom, 2007</em><sup><a href="#fn15-13914" id="fnr15-13914" title="see footnote" className="footnote">15</a></sup></p>
			</blockquote>

			<h2>All linked by information</h2>

			<figure>
			<img src="https://imgs.xkcd.com/comics/wikipedian_protester.png" alt="" />
			</figure>

			<p>It can be argued, that the human &quot;need&quot; to receive, transfer and share information as a survival mechanism found its logical continuation in the internet. The efficient transfer from speech, to text in its physical form to a fluid accessible digital form divided in bits and bytes delivered to our screens is a causality follow by an ideology of constant progress as a society and species. But in this regard, I'm confused by what &quot;progress&quot; actually is: </p>
			<div className="embed-container"><iframe src="https://player.vimeo.com/video/191817381#t=23m26s" width="640" height="358" frameBorder="0" allow="autoplay; fullscreen"></iframe></div>

			<p><br/>
			<em>Adam Curtis, 2016</em>, 23:26 – 26:55<sup><a href="#fn16-13914" id="fnr16-13914" title="see footnote" className="footnote">16</a></sup></p>

			<h2>Who is my avatar</h2>

			<p>Various science fiction writers described utopian or dystopian worlds in which the society in it is deprived of reflection on their guiding systems. Like in &quot;Brave new world&quot; by Aldous Huxley in which the actors of a society are pressuring each other to take the happiness-producing drug &quot;soma&quot;. When you compare this drug to the pressure of availability and representation on social media platforms like Facebook and Instagram on which everyone is happy, everyone is successful and everyone is doing great things in their individual lives, we're practically already doing the same thing. We force upon our individual selves the pressure of capitalization and quantification of each and every aspect of our lives, to show our peers that we're worth the &quot;social capital&quot; that we represent. But the dissonance between our presented selves and how – we think – we are is an age old discussion in sociology and psychology also along the line of how we perceive ourselves. Social media gives us the means to do this in an orderly and structured fashion. You have the same amount of space like everyone else to fill up with as many of things that you see fit to &quot;correctly&quot; show us who you actually are – or you would like us to believe who you are.</p>

			<p>In his book &quot;Alienation and Acceleration&quot;[^], Hartmut Rosa argues that the promise of the moderne era is the autonomy to decide – individually and collectively – what self-determination is. How much power do we <em>want</em> to </p>

			<div className="footnotes">
			<hr />
			<ol>

			<li id="fn1-13914">
			<p>which is – when this project works in the intended way – now and in the future <a href="#fnr1-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn2-13914">
			<p>In my case right now: the German speaking part of Switzerland in April 2019 <a href="#fnr2-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn3-13914">
			<p>like the <a href="https://en.wikipedia.org/wiki/Cambridge_Analytica">Facebook–Cambridge Analytica data scandal 2018</a>, the leaks surrounding <a href="https://en.wikipedia.org/wiki/Global_surveillance_disclosures_(2013%E2%80%93present)">surveilance</a> which are on an all time high since the <a href="https://en.wikipedia.org/wiki/Edward_Snowden#Global_surveillance_disclosures">Snowden leaks in 2013</a>, the list is long... <a href="#fnr3-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn4-13914">
			<p>a <a href="https://en.wikipedia.org/wiki/Version_control">version control system</a> used and misused by programmers all over the world for sharing and collaborating on a variety of code based projects <a href="#fnr4-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn5-13914">
			<p><a href="http://web.mit.edu/allanmc/www/foucault1.pdf">Michel Foucault, 1967, <em>Of Other Spaces: Utopias and Heterotopias</em></a>, from <em>Architecture / Mouvement / Continuité</em>, October, 1984;(“Des Espace Autres,” March 1967 Translated from the French by Jay Miskowiec), p. 3-4 <a href="#fnr5-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn6-13914">
			<p>at least, not anymore since the era of the &quot;internet cafes&quot; died in the early 2000s <a href="#fnr6-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn7-13914">
			<p><a href="http://web.mit.edu/allanmc/www/foucault1.pdf">Michel Foucault, 1967, <em>Of Other Spaces: Utopias and Heterotopias</em></a>, from <em>Architecture / Mouvement / Continuité</em>, 1984; (“Des Espace Autres,” March 1967 Translated from the French by Jay Miskowiec), p. 7 <a href="#fnr7-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn8-13914">
			<p>this is going to be crucial to update in the future! Who knows when the next thing will take over... <a href="#fnr8-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn9-13914">
			<p>The fact that you're reading this right now on a website, in a browser, on a device (like a computer or a smartphone) implies that you're at least to a certain extend part of this <a href="#fnr9-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn10-13914">
			<p><a href="https://youtu.be/w3_0x6oaDmI"><em>Computerphile, Tom Scott, 2014: Why Electronic Voting is a BAD Idea</em>, YouTube</a> <a href="#fnr10-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn11-13914">
			<p>Matt Webb, 2012, <em>The near future inventor</em> in: <a href="https://roryhyde.com/Future-Practice">Rory Hyde, <em>Future Practice: Conversations from the Edge of Architecture</em></a>, New York: Routledge, 2012 <a href="#fnr11-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn12-13914">
			<p><a href="https://courses.ischool.berkeley.edu/i290-tpl/s11/w/images/6/69/The_Moral_Dilemmas_of_a_Safety-belt.pdf">Bruno Latour, 1989: <em>La Ceinture de sécurité”</em>, in Alliage N°1 p.21-27. Traduction inédite en anglais, unpublished English translation by Lydia Davis</a>, p. 6 <a href="#fnr12-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn13-13914">
			<p><a href="https://vimeo.com/300725472">Adam Curtis, 2016: <em>All Watched Over by Machines of Loving Grace - Episode 2 - The Use and Abuse of Vegetational Concepts</em>, BBC</a>, 28:00 – 36:05 <a href="#fnr13-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn14-13914">
			<p>Like the many times programs operated by <a href="https://en.wikipedia.org/wiki/Machine_learning">&quot;machine learning&quot;</a> – to which people often falsely refer to as <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">&quot;A.I.&quot;</a> – created <a href="https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist">racist</a> or <a href="https://www.technologyreview.com/s/612876/this-is-how-ai-bias-really-happensand-why-its-so-hard-to-fix/">biased</a> outcomes <a href="#fnr14-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn15-13914">
			<p><a href="https://nickbostrom.com/ethics/dignity-enhancement.pdf">Nick Bostrom, 2007, <em>Dignity and Enhancement</em></a>, p. 30 <a href="#fnr15-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			<li id="fn16-13914">
			<p><a href="https://vimeo.com/191817381">Adam Curtis, 2016: <em>HyperNormalisation</em>, BBC</a>, 23:26 – 26:55 <a href="#fnr16-13914" title="return to article" className="reversefootnote">&#8617;&#xFE0E;</a></p>
			</li>

			</ol>
			</div>
			</article>
			);
}

}